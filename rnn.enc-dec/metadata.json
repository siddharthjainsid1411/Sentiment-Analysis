{
  "model": {
    "src_vocab_size": 600,
    "tgt_vocab_size": 600,
    "embd_dims": 512,
    "hidden_size": 1024,
    "dropout": 0.2,
    "num_layers": 2
  },
  "data": {
    "src_padding": null,
    "tgt_padding": 25
  },
  "training": {
    "num_epochs": 15,
    "batch_size": 16,
    "shuffle": true,
    "save_steps": 200,
    "eval_steps": 150
  }
}